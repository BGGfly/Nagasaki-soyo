# Nagasaki-soyo
come from nuaa HeYuan 37 
-----------------------------------------------------------2025/09/21 22：03---------------------------------------------------------------

更改：
    1.前进行特征提取的时候，进行可视化的时候，也是没有正常轴承对应的值，原始数据集中“正常”类别的样本数量极度稀少，导致数据严重不平衡。
当一个类别的样本太少时：箱线图 (Box Plot) 会变得没有统计意义，可能只显示为一条线，无法看出分布情况。t-SNE图 中，这个稀有类别的几个点很容易被淹没在其他大量的点中，
或者被错误地拉入其他大类别的簇里，从而给一种“特征无法区分正常样本”的错觉。先对数据进行过采样 (Oversampling)，人为地增加稀有类别的样本数量，使得所有类别在可视化时“势均力敌”。
使用 SMOTE (Synthetic Minority Over-sampling Technique) 技术。
    2.生成source_data_metadata.csv文件时SamplingFreq_Hz 和 BearingLocation 字段没有被正确解析。根源在于从文件路径中提取采样频率和轴承位置的逻辑不够完善。
原来的代码要求文件夹名称必须同时包含频率（如48khz）和轴承位置（如_de_data或_fe_data）这两个信息。
对于故障数据，文件夹名是 12khz_de_data，满足条件，所以解析成功。对于正常数据，文件夹名是 48kHz_Normal_data，它只包含了频率信息，没有包含 de 或 fe，导致代码跳过了它，未能提取出采样频率。
解决方案：修正路径解析逻辑
找到包含 khz 的文件夹部分。从中提取出频率。如果这个文件夹部分还包含 de 或 fe，那么再提取位置信息。


使用smote过采样后生成的文件以***_somte.***命名。

-----------------------------------------------------------2025/09/21 22：03---------------------------------------------------------------


-----------------------------------------------------------2025/09/22 13：06 问题三---------------------------------------------------------------
三：迁移诊断。
    本阶段的核心目标是构建一个迁移学习模型，这个模型需要克服源域（试验台，高转速）和目标域（实际列车，低转速）之间的转速不匹配问题，并最终对16个无标签的目标域文件进行故障诊断。
采用先进的深度迁移学习方案，具体来说是域对抗神经网络 (Domain Adversarial Neural Network, DANN)。
    我们将分步完成以下工作流：
1.准备数据：编写一个Python脚本 (dann_data_loader.py)，创建能够同时加载源域和目标域数据的数据管道。
    代码：dann_data_loader.py。它的作用是定义一个 Dataset 类，并创建能够同时为模型提供源域和目标域数据的数据加载器（DataLoader）。
    执行：
        成功加载并处理了源域和目标域的所有 .mat 文件。将源域数据按照80/20的比例，划分为了训练集 (22767个样本) 和测试集 (5691个样本)。
        最终成功创建了我们后续训练所需的所有三个数据加载器 (source_train_loader, source_test_loader, target_loader)。
2.构建模型：编写一个脚本 (dann_model.py)，使用PyTorch定义DANN模型的完整架构。
    创建一个名为 dann_model.py 的新脚本文件。这个文件将包含DANN模型的完整定义，包括特征提取器、标签分类器、域分类器以及核心的梯度反转层。
    代码定义了迁移学习所需的所有神经网络组件：
    FeatureExtractor: 核心的1D卷积网络，用于从原始信号中自动学习特征。
    Classifier: 一个通用的全连接网络，用于分类任务。
    DANN: 将上述组件和梯度反转层（GRL）组装起来，形成最终的对抗网络。
2.5
    至此，完成任务三的所有“准备工作”：
    a.数据管道 (dann_data_loader.py)：可以持续、高效地提供源域和目标域的数据。
    b.模型架构 (dann_model.py)：定义了我们进行学习所需的神经网络结构。
    最后：编写主训练脚本 train_dann.py。导入我们之前创建的数据加载器和模型，实现核心的对抗训练循环，并在训练过程中监控性能、保存最佳模型。
3.训练模型：编写主训练脚本 (train_dann.py)，实现对抗训练循环，并保存训练好的最终模型。
    3.1
        修改 train_dann.py: 增加代码，用于记录并绘制训练全过程的损失（Loss）和准确率（Accuracy）曲线。
        创建一个新的分析脚本：编写一个 evaluate_and_visualize.py 脚本，用于加载训练好的最佳模型，并生成更深入的性能分析图，包括混淆矩阵和最重要的t-SNE特征分布图
4.预测与分析：编写一个脚本 (predict_target.py)，加载训练好的模型，对16个目标域文件进行预测，并对迁移结果进行可视化分析。


-----------------------------------------------------------2025/09/22 13：06 问题三---------------------------------------------------------------
